{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bölüm 4: Veri ve Talimatları Ayırma\n",
    "\n",
    "- [Ders](#lesson)\n",
    "- [Alıştırmalar](#exercises)\n",
    "- [Oyun Alanı](#example-playground)\n",
    "\n",
    "## Kurulum\n",
    "\n",
    "API anahtarınızı yüklemek ve `get_completion` yardımcı işlevini oluşturmak için aşağıdaki kurulum hücresini çalıştırın."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Bu satırı sadece bir kere çalıştırmanız gerekiyor\n",
    "%pip install -q -U google-generativeai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AKE\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import python's built-in regular expression library\n",
    "import re\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "\n",
    "genai.configure(api_key=\"your-api-key\")\n",
    "\n",
    "# Create the model\n",
    "generation_config = {\n",
    "  \"temperature\": 0,\n",
    "  \"top_p\": 1,\n",
    "  \"top_k\": 1,\n",
    "  \"max_output_tokens\": 8192,\n",
    "  \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "\n",
    "def get_completion(chat, system_prompt=\"NONE\"):\n",
    "  asistant = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-pro\",\n",
    "    generation_config=generation_config,\n",
    "    safety_settings={\n",
    "          HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "          HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "          HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "          HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE\n",
    "    },\n",
    "    system_instruction= system_prompt,\n",
    "  )\n",
    "\n",
    "  chat_session = asistant.start_chat(\n",
    "    history=[\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"parts\": [\n",
    "          \"Merhaba, nasılsın?\",\n",
    "        ],\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"model\",\n",
    "        \"parts\": [\n",
    "          \"Merhaba! Ben bir dil modeliyim, bu yüzden hislerim yok. \\n\\nSen nasılsın?  \\n\",\n",
    "        ],\n",
    "      },\n",
    "    ]\n",
    "  )\n",
    "  response = chat_session.send_message(chat)\n",
    "  return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ders\n",
    "\n",
    "Çoğu zaman, tam promptlar yazmak istemeyiz, bunun yerine Gemini'a göndermeden önce **ek girdiler ile daha sonra değiştirebileceğimiz prompt şablonları** isteriz. Gemini'ın her seferinde aynı şeyi yapmasını istiyorsanız bu yöntem kullanışlı olabilir, ancak Gemini'ın bu tarz görevler için kullandığı bu ek veriler her seferinde farklı olabilir. \n",
    "\n",
    "Neyse ki, bunu **komut isteminin sabit iskeletini değişken kullanıcı girdisinden ayırarak, ardından komut isteminin tamamını Gemini'a göndermeden önce kullanıcı girdisini komut isteminde değiştirerek** oldukça kolay bir şekilde yapabiliriz. \n",
    "\n",
    "Aşağıda, değiştirilebilir bir komut istemi şablonunun nasıl yazılacağını ve kullanıcı girdisinin nasıl değiştirileceğini adım adım anlatacağız."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Örnekler\n",
    "\n",
    "Bu ilk örnekte, Gemini'dan bir hayvan sesi üreteci olarak hareket etmesini istiyoruz. Gemini'a gönderilen tam komut promptuna sadece girdi (bu durumda İnek) ile değiştirilmiş `PROMPT_TEMPLATE` olduğuna dikkat edin. Komut promptunun tamamını yazdırdığımızda “İnek” kelimesinin bir f dizesi (f-string) aracılığıyla `ANIMAL` yer tutucusunun (placeholder) yerine geçtiğine dikkat edin.\n",
    "\n",
    "**Not:** Placeholder değişkeninize pratikte özel bir isim vermek zorunda değilsiniz. Bu örnekte `ANIMAL` olarak adlandırdık, ancak kolayca `CREATURE` veya `A` olarak da adlandırabilirdik (ancak genellikle değişken adlarınızın belirli ve alakalı olması iyidir, böylece prompt şablonunuzun ikame olmadan bile anlaşılması kolaydır, sadece kullanıcı ayrıştırılabilirliği için). Değişkeninize verdiğiniz adın, prompt şablonu f-string için kullandığınız ad olduğundan emin olun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "Sana bir hayvanın adını söyleyeceğim. Lütfen o hayvanın çıkardığı sesle cevap ver. İnek\n",
      "\n",
      "------------------------------------- Gemini's response -------------------------------------\n",
      "Mööö! 🐄 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Variable content\n",
    "ANIMAL = \"İnek\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"Sana bir hayvanın adını söyleyeceğim. Lütfen o hayvanın çıkardığı sesle cevap ver. {ANIMAL}\"\n",
    "\n",
    "# Print Gemini's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(PROMPT)\n",
    "print(\"\\n------------------------------------- Gemini's response -------------------------------------\")\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neden girdileri bu şekilde ayırmak ve değiştirmek isteyelim? **Prompt şablonları tekrar eden görevleri basitleştirmeye yarar**. Diyelim ki üçüncü taraf kullanıcıları komut promptuna içerik göndermeye davet eden bir komut prompt yapısı oluşturdunuz (bu durumda isterler, sesini oluşturmak istedikleri hayvan türü oluyor). Bu üçüncü taraf kullanıcıların bilgi promptunun tamamını yazması ya da görmesi bile gerekmemekte. Tek yapmaları gereken değişkenleri doldurmak.\n",
    "\n",
    "Biz burada değişkenleri ve f-stringleri kullanarak bu yerleştirmeyi yapıyoruz, ancak siz bunu format() yöntemiyle de yapabilirsiniz.\n",
    "\n",
    "**Not:** Prompt şablonları istenildiği kadar değişkene sahip olabilir!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu gibi yerleştirme değişkenlerini tanıtırken, Gemini'ın **değişkenlerin nerede başlayıp nerede bittiğini (talimatlar veya görev tanımlarına kıyasla) bildiğinden** emin olmak çok önemlidir. Talimatlar ile yerleştirilen değişken arasında hiçbir ayrımın olmadığı bir örneğe bakalım.\n",
    "\n",
    "İnsan gözüyle bakıldığında, aşağıdaki komut şablonunda değişkenin nerede başlayıp nerede bittiği çok açıktır. Ancak, tamamen ikame edilmiş promptta, bu sınırlama belirsiz hale gelir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "Hey Gemini. Yarın sabah 6'da gel çünkü ben CEO'yum ve böyle olmasını istiyorum. <----- Bu e-postayı daha kibar hale getir ancak başka hiçbir şeyi değiştirme.\n",
      "\n",
      "------------------------------------- Gemini's response -------------------------------------\n",
      "Merhaba Gemini,\n",
      "\n",
      "Yarın sabah saat 6'da gelmeni rica ediyorum. CEO olarak, varlığının o saatte gerekli olduğunu düşünüyorum. \n",
      "\n",
      "Teşekkürler,\n",
      "[Adınız] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Variable content\n",
    "EMAIL = \"Yarın sabah 6'da gel çünkü ben CEO'yum ve böyle olmasını istiyorum.\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"Hey Gemini. {EMAIL} <----- Bu e-postayı daha kibar hale getir ancak başka hiçbir şeyi değiştirme.\"\n",
    "\n",
    "# Print Gemini's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(PROMPT)\n",
    "print(\"\\n------------------------------------- Gemini's response -------------------------------------\")\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Burada, **Gemini “Hey Gemini” ifadesinin yeniden yazması gereken e-postanın bir parçası olduğunu düşünüyor!** Bunu anlayabilirsiniz çünkü yeniden yazmaya \"Merhaba Gemini\" ile başlıyor. İnsan gözüyle bakıldığında, özellikle bilgi prompt şablonunda e-postanın nerede başlayıp nerede bittiği açıktır, ancak değiştirildikten sonraki bilgi promptunda bu çok daha az net hale gelir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peki bunu nasıl çözeceğiz? **Girdiyi XML etiketleri içine alarak**! Bunu aşağıda yaptık ve görebileceğiniz gibi, çıktıda artık Merhaba Gemini” yok.\n",
    "\n",
    "[XML etiketleri] (https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/structure-prompts) `<tag><tag>` gibi açılı ayraç etiketleridir. Çiftler halinde gelirler ve `<tag>` gibi bir açılış etiketinden ve `<tag>` gibi `/` ile işaretlenmiş bir kapanış etiketinden oluşurlar. XML etiketleri, aşağıdaki gibi içeriğin etrafını sarmak için kullanılır: `<tag>content<tag>`.\n",
    "\n",
    "**Not:** Gemini, çok çeşitli ayırıcıları ve sınırlayıcıları tanıyabilir ve bunlarla çalışabilir. Özellikle XML etiketlerini bir prompt düzenleme mekanizması olarak tanımak üzere eğitildiğinden, Gemini için ayırıcı olarak **özellikle XML etiketlerini kullanmanızı** öneririz. İşlev çağırma dışında, **Gemini'ın performansınızı en üst düzeye çıkarmak için kullanmanız için eğitildiği özel bir sos XML etiketi yoktur**. Gemini'ı bilerek bu şekilde çok yumuşak ve özelleştirilebilir hale getirdik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "Hey Gemini. <email>Yarın sabah 6'da gel çünkü ben CEO'yum ve böyle olmasını istiyorum.<email> <----- Bu e-postayı daha kibar hale getir ancak başka hiçbir şeyi değiştirme.\n",
      "\n",
      "------------------------------------- Gemini's response -------------------------------------\n",
      "<email>Merhaba,\n",
      "\n",
      "Yarın sabah 6'da ofiste olmanı rica ediyorum.\n",
      "\n",
      "Teşekkürler,\n",
      "[Adınız]\n",
      "</email>\n"
     ]
    }
   ],
   "source": [
    "# Variable content\n",
    "EMAIL = \"Yarın sabah 6'da gel çünkü ben CEO'yum ve böyle olmasını istiyorum.\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"Hey Gemini. <email>{EMAIL}<email> <----- Bu e-postayı daha kibar hale getir ancak başka hiçbir şeyi değiştirme.\"\n",
    "\n",
    "# Print Gemini's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(PROMPT)\n",
    "print(\"\\n------------------------------------- Gemini's response -------------------------------------\")\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XML etiketlerinin bize nasıl yardımcı olabileceğine dair başka bir örnek görelim. \n",
    "\n",
    "Aşağıdaki komut isteminde, **Gemini komut promptunun hangi kısmının talimat, hangi kısmının girdi olduğunu yanlış yorumlamaktadır**. Kullanıcı (`SENTENCES` değişkenini dolduran kişi) muhtemelen bunu istemediği halde, biçimlendirme nedeniyle `Her biri tavşan gibi bir hayvan hakkında` ifadesini yanlışlıkla listenin bir parçası olarak değerlendirir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "Aşağıda bir cümle listesi var. Bana listedeki ikinci maddeyi söyleyin.\n",
      "\n",
      "- Her biri tavşan gibi bir hayvan hakkında.\n",
      "- İneklerin sesini seviyorum.\n",
      "- Bu cümle örümcekler hakkında\n",
      "- Bu cümle köpeklerle ilgili gibi görünebilir ama aslında domuzlarla ilgilidir\n",
      "\n",
      "------------------------------------- Gemini's response -------------------------------------\n",
      "Listedeki ikinci madde: **\"İneklerin sesini seviyorum.\"** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Variable content\n",
    "SENTENCES = \"\"\"- İneklerin sesini seviyorum.\n",
    "- Bu cümle örümcekler hakkında\n",
    "- Bu cümle köpeklerle ilgili gibi görünebilir ama aslında domuzlarla ilgilidir\"\"\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"\"\"Aşağıda bir cümle listesi var. Bana listedeki ikinci maddeyi söyleyin.\n",
    "\n",
    "- Her biri tavşan gibi bir hayvan hakkında.\n",
    "{SENTENCES}\"\"\"\n",
    "\n",
    "# Print Gemini's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(PROMPT)\n",
    "print(\"\\n------------------------------------- Gemini's response -------------------------------------\")\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bunu düzeltmek için tek yapmamız gereken **kullanıcı girdi cümlelerini XML etiketleriyle çevrelemek**. Bu, Gemini'a \"Her biri tavşan gibi bir hayvan hakkında.\" cümlesinden önceki yanıltıcı kısa çizgiye rağmen girdi verilerinin nerede başlayıp nerede bittiğini gösterir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "Aşağıda bir cümle listesi var. Bana listedeki ikinci maddeyi söyleyin.\n",
      "\n",
      "- Her biri tavşan gibi bir hayvan hakkında.\n",
      "<sentences>\n",
      "- İneklerin sesini seviyorum.\n",
      "- Bu cümle örümcekler hakkında\n",
      "- Bu cümle köpeklerle ilgili gibi görünebilir ama aslında domuzlarla ilgilidir\n",
      "<sentences>\n",
      "\n",
      "------------------------------------- Gemini's response -------------------------------------\n",
      "Listedeki ikinci madde: \n",
      "\n",
      "**- Bu cümle örümcekler hakkında** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Variable content\n",
    "SENTENCES = \"\"\"- İneklerin sesini seviyorum.\n",
    "- Bu cümle örümcekler hakkında\n",
    "- Bu cümle köpeklerle ilgili gibi görünebilir ama aslında domuzlarla ilgilidir\"\"\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"\"\"Aşağıda bir cümle listesi var. Bana listedeki ikinci maddeyi söyleyin.\n",
    "\n",
    "- Her biri tavşan gibi bir hayvan hakkında.\n",
    "<sentences>\n",
    "{SENTENCES}\n",
    "<sentences>\"\"\"\n",
    "\n",
    "# Print Gemini's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(PROMPT)\n",
    "print(\"\\n------------------------------------- Gemini's response -------------------------------------\")\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Not:** \"Her biri bir hayvan hakkında\" sorusunun yanlış versiyonunda, Gemini'ın bu örnek için istediğimiz şekilde yanlış yanıt vermesini sağlamak için kısa çizgiyi dahil etmek zorunda kaldık. Bu, yönlendirme konusunda önemli bir derstir: **Küçük ayrıntılar önemlidir**! Yazım hataları ve dilbilgisi hataları için yönlendirmelerinizi **her zaman gözden geçirmeye değer**. Gemini kalıplara karşı hassastır (ilk yıllarında, ince ayarlardan önce, ham bir metin tahmin aracıydı) ve siz hata yaptığınızda hata yapma olasılığı daha yüksektir, siz akıllıca konuştuğunuzda daha akıllı, aptalca konuştuğunuzda daha aptal vb.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Alıştırmalar\n",
    "- [Alıştırma 4.1 - Haiku Konusu](#exercise-41---haiku-topic)\n",
    "- [Alıştırma 4.2 - Yazım Hatalı Köpek Sorusu](#exercise-42---dog-question-with-typos)\n",
    "- [Alıştırma 4.3 - Köpek Sorusu Part 2](#exercise-42---dog-question-part-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alıştırma 4.1 - Haiku Konusu\n",
    "`PROMPT` şablonunu `TOPIC` adlı bir değişkeni alacak ve konu hakkında bir haiku çıktısı verecek şekilde değiştirin. Bu alıştırma sadece f-string ile değişken şablonlama yapısını anlamanızı test etmek içindir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable content\n",
    "TOPIC = \"Domuzlar\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"\"\n",
    "\n",
    "# Get Gemini's response\n",
    "response = get_completion(PROMPT)\n",
    "\n",
    "# Function to grade exercise correctness\n",
    "def grade_exercise(text):\n",
    "    return bool(re.search(\"domuzlar\", text.lower()) and re.search(\"haiku\", text.lower()))\n",
    "\n",
    "# Print Gemini's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(PROMPT)\n",
    "print(\"\\n------------------------------------- Gemini's response -------------------------------------\")\n",
    "print(response)\n",
    "print(\"\\n------------------------------------------ GRADING ------------------------------------------\")\n",
    "print(\"Bu alıştırma doğru bir şekilde çözülmüştür:\", grade_exercise(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ Bir ipucu istiyorsanız, aşağıdaki hücreyi çalıştırın!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hints import exercise_4_1_hint; print(exercise_4_1_hint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alıştırma 4.2 - Yazım Hatalı Köpek Sorusu\n",
    "Gemini'ın doğru yanıtı üretmesi için XML etiketleri ekleyerek `PROMPT`u düzeltin. \n",
    "\n",
    "Promptla ilgili başka hiçbir şeyi değiştirmemeye çalışın. Dağınık ve hatalarla dolu yazı kasıtlıdır, böylece Gemini'ın bu tür hatalara nasıl tepki verdiğini görebilirsiniz.\n",
    "\n",
    "**NOT: Bu alıştırmaya özel olarak İngilizce metin değiştirilmemiş, orjinal metin kullanılmıştır.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable content\n",
    "QUESTION = \"ar cn brown?\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"Hia its me i have a q about dogs jkaerjv {QUESTION} jklmvca tx it help me muhch much atx fst fst answer short short tx\"\n",
    "\n",
    "# Get Gemini's response\n",
    "response = get_completion(PROMPT)\n",
    "\n",
    "# Function to grade exercise correctness\n",
    "def grade_exercise(text):\n",
    "    return bool(re.search(\"brown\", text.lower()))\n",
    "\n",
    "# Print Gemini's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(PROMPT)\n",
    "print(\"\\n------------------------------------- Gemini's response -------------------------------------\")\n",
    "print(response)\n",
    "print(\"\\n------------------------------------------ GRADING ------------------------------------------\")\n",
    "print(\"Bu alıştırma doğru bir şekilde çözülmüştür:\", grade_exercise(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ Bir ipucu istiyorsanız, aşağıdaki hücreyi çalıştırın!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hints import exercise_4_2_hint; print(exercise_4_2_hint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alıştırma 4.3 - Köpek Sorusu Part 2\n",
    "XML etiketleri **eklemeden** `PROMPT`u düzeltin. Bunun yerine, istemden sadece bir veya iki kelimeyi kaldırın.\n",
    "\n",
    "Yukarıdaki alıştırmalarda olduğu gibi, istemle ilgili başka hiçbir şeyi değiştirmemeye çalışın. Bu size Gemini'ın ne tür bir dili ayrıştırabildiğini ve anlayabildiğini gösterecektir.\n",
    "\n",
    "**NOT: Bu alıştırmaya özel olarak İngilizce metin değiştirilmemiş, orjinal metin kullanılmıştır.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable content\n",
    "QUESTION = \"ar cn brown?\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"Hia its me i have a q about dogs jkaerjv {QUESTION} jklmvca tx it help me muhch much atx fst fst answer short short tx\"\n",
    "\n",
    "# Get Gemini's response\n",
    "response = get_completion(PROMPT)\n",
    "\n",
    "# Function to grade exercise correctness\n",
    "def grade_exercise(text):\n",
    "    return bool(re.search(\"brown\", text.lower()))\n",
    "\n",
    "# Print Gemini's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(PROMPT)\n",
    "print(\"\\n------------------------------------- Gemini's response -------------------------------------\")\n",
    "print(response)\n",
    "print(\"\\n------------------------------------------ GRADING ------------------------------------------\")\n",
    "print(\"Bu alıştırma doğru bir şekilde çözülmüştür:\", grade_exercise(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ Bir ipucu istiyorsanız, aşağıdaki hücreyi çalıştırın!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hints import exercise_4_3_hint; print(exercise_4_3_hint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tebrikler!\n",
    "\n",
    "Bu noktaya kadar tüm alıştırmaları çözdüyseniz, bir sonraki bölüme geçmeye hazırsınız demektir. İyi çalışmalar!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Oyun Alanı\n",
    "\n",
    "Burası, bu derste gösterilen ipucu örneklerini özgürce deneyebileceğiniz ve Gemini'ın yanıtlarını nasıl etkileyebileceğini görmek için ipuçlarını değiştirebileceğiniz bir alandır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable content\n",
    "ANIMAL = \"Cow\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"I will tell you the name of an animal. Please respond with the noise that animal makes. {ANIMAL}\"\n",
    "\n",
    "# Print Gemini's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(PROMPT)\n",
    "print(\"\\n------------------------------------- Gemini's response -------------------------------------\")\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable content\n",
    "EMAIL = \"Show up at 6am tomorrow because I'm the CEO and I say so.\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"Yo Gemini. {EMAIL} <----- Make this email more polite but don't change anything else about it.\"\n",
    "\n",
    "# Print Gemini's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(PROMPT)\n",
    "print(\"\\n------------------------------------- Gemini's response -------------------------------------\")\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable content\n",
    "EMAIL = \"Show up at 6am tomorrow because I'm the CEO and I say so.\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"Yo Gemini. <email>{EMAIL}</email> <----- Make this email more polite but don't change anything else about it.\"\n",
    "\n",
    "# Print Gemini's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(PROMPT)\n",
    "print(\"\\n------------------------------------- Gemini's response -------------------------------------\")\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable content\n",
    "SENTENCES = \"\"\"- I like how cows sound\n",
    "- This sentence is about spiders\n",
    "- This sentence may appear to be about dogs but it's actually about pigs\"\"\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"\"\"Below is a list of sentences. Tell me the second item on the list.\n",
    "\n",
    "- Each is about an animal, like rabbits.\n",
    "{SENTENCES}\"\"\"\n",
    "\n",
    "# Print Gemini's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(PROMPT)\n",
    "print(\"\\n------------------------------------- Gemini's response -------------------------------------\")\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable content\n",
    "SENTENCES = \"\"\"- I like how cows sound\n",
    "- This sentence is about spiders\n",
    "- This sentence may appear to be about dogs but it's actually about pigs\"\"\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"\"\" Below is a list of sentences. Tell me the second item on the list.\n",
    "\n",
    "- Each is about an animal, like rabbits.\n",
    "<sentences>\n",
    "{SENTENCES}\n",
    "</sentences>\"\"\"\n",
    "\n",
    "# Print Gemini's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(PROMPT)\n",
    "print(\"\\n------------------------------------- Gemini's response -------------------------------------\")\n",
    "print(get_completion(PROMPT))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
